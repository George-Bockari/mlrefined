{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using basic Bag of Words features for text mining applications\n",
    "\n",
    "This notebook is based on the excellent Kaggle tutorial [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words), which details how to use various Python libraries to preprocess text data for NLP tasks like sentiment analysis, document clustering, and the like.  \n",
    "\n",
    "This preprocessing includes:\n",
    "- removing all html all tags from each document\n",
    "- parsing the text of each document (separating it out into individual words)\n",
    "- removing stop words (words of little meaning like 'and' and 'the')\n",
    "- stemming (combining words of similar meaning like 'dogs' and 'dog')\n",
    "- making a word-frequency representations (a.k.a. a Bag of Words feature vector) of a document preprocessed in the manner above\n",
    "\n",
    "This notebook also employs the exemplary dataset used in the tutorial - one consisting of movie reviews - labeled as either 'positive' (meaning the person enjoyed the film) or 'negative'.  These reviews are in raw html form (hence the need for tag-stripping etc.,).  \n",
    "\n",
    "Once all documents are pre-processed (once each movie review is transformed into a Bag of Words feature vector) we can then train a supervised learning model to distinguish between positive and negative reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Nurgetson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# a class contaniing all necessary functions to transform raw html documents into Bag of Words feature vectors\n",
    "from sentiment_analyzer import sentiment_analyzer\n",
    "sentiment_analyzer = sentiment_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in our training and testing datasets consisting of 20,000 and 5,000 movie reviews respectively. Each review has a label of 'positive' or 'negative'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### we'll need to split this into training and testing sets ourselves\n",
    "# load in training data\n",
    "csvname = \"training_data.tsv\"\n",
    "training_data,training_labels = sentiment_analyzer.load_data(csvname)\n",
    "\n",
    "# load in testing data\n",
    "csvname = \"testing_data.tsv\"\n",
    "testing_data,testing_labels = sentiment_analyzer.load_data(csvname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the raw data - notice the many html tags that need removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a raw document from the training set - those from the testing set look the same\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we clean both the training and testing datasets - this means we\n",
    "\n",
    "- removing all html all tags from each document\n",
    "- parsing the text of each document (separating it out into individual words)\n",
    "- removing stop words (words of little meaning like 'and' and 'the'), punctuation, numbers\n",
    "- stemming (combining words of similar meaning like 'dogs' and 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nurgetson/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# clean training data \n",
    "clean_training_data = sentiment_analyzer.clean_data(training_data)\n",
    "\n",
    "# clean testing data\n",
    "clean_testing_data = sentiment_analyzer.clean_data(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that each dataset has been cleaned we can transform the documents from each into Bag of Words features.  Note: we need to create this transformation based on the **training data** alone, as the dictionary (the set of words shared by documents in the training set) used here will be the one on which we train our supervised learning algorithm.  Hence any future testing data must be transformed in the same way for us to be able to apply the learned training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit a BoW transform to the cleaned documents\n",
    "BoW_transform = sentiment_analyzer.make_BoW_transform(clean_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the newly formed BoW transformation to transform both training and testing sets\n",
    "# normalize BoW data\n",
    "import sklearn\n",
    "training_BoW_features = BoW_transform.transform(clean_training_data)\n",
    "training_BoW_features = training_BoW_features.toarray()\n",
    "training_BoW_features = sklearn.preprocessing.normalize(training_BoW_features,axis = 1)\n",
    "\n",
    "testing_BoW_features = BoW_transform.transform(clean_testing_data)\n",
    "testing_BoW_features = testing_BoW_features.toarray()\n",
    "testing_BoW_features = sklearn.preprocessing.normalize(testing_BoW_features,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training boosted classifier\n",
      "accuracy on training set is 0.8383\n",
      "accuracy on testing set is 0.834\n"
     ]
    }
   ],
   "source": [
    "# perform classification on training set, report accuracy on training and testing sets\n",
    "sentiment_analyzer.perform_classification(training_BoW_features,training_labels,testing_BoW_features,testing_labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
